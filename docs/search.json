[
  {
    "objectID": "wiki.html",
    "href": "wiki.html",
    "title": "Wiki",
    "section": "",
    "text": "Hello, Systematic Reviewers!\nWelcome to the CAMARADES Preclinical Systematic Review & Meta-Analysis Wiki.\nFind information, links, articles, and useful tools to guide you through your review.\nNavigate through the sections to find out more about what a preclinical systematic review is, what the steps are, and how to complete them.\nUse the table of contents bar on the left side of the screen to navigate along the steps of a systematic review.\nIf you have questions about the resources, or would like to ask a question about your specific review, please get in touch: Email us here"
  },
  {
    "objectID": "wiki-content/12-publication.html",
    "href": "wiki-content/12-publication.html",
    "title": "Interpretation & Publication",
    "section": "",
    "text": "Once you have conducted your systematic review, and potentially also conducted a meta-analysis, it is time to tell the community what you found and ensure the findings from your review reach your audience.",
    "crumbs": [
      "Interpretation & Publication"
    ]
  },
  {
    "objectID": "wiki-content/12-publication.html#grade-approach",
    "href": "wiki-content/12-publication.html#grade-approach",
    "title": "Interpretation & Publication",
    "section": "GRADE Approach",
    "text": "GRADE Approach\nBe careful when interpreting the results; acknowledge sources of bias; consider heterogeneity, generalisability, and relevance.\nIt may help to use the Preclinical Grade approach Hooijmans et al., 2018 to rate the certainty of the evidence of preclinical animal studies, in the context of therapeutic interventions.",
    "crumbs": [
      "Interpretation & Publication"
    ]
  },
  {
    "objectID": "wiki-content/12-publication.html#transparent-reporting",
    "href": "wiki-content/12-publication.html#transparent-reporting",
    "title": "Interpretation & Publication",
    "section": "Transparent Reporting",
    "text": "Transparent Reporting\nReport your systematic review in a way that allows reproducibility of the results and future updating.\nWe recommend following the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA-2020) Guidelines. The checklist can be found here. In addition, we recommend using the PRISMA Flowchart to visualise the studies in your systematic review process. The PRISMA Flowchart template can be found here.",
    "crumbs": [
      "Interpretation & Publication"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html",
    "href": "wiki-content/10-metaanalysis.html",
    "title": "Meta-Analysis",
    "section": "",
    "text": "A meta-analysis is the statistical combination of results from two or more separate studies.",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#what-is-meta-analysis",
    "href": "wiki-content/10-metaanalysis.html#what-is-meta-analysis",
    "title": "Meta-Analysis",
    "section": "",
    "text": "A meta-analysis is the statistical combination of results from two or more separate studies.",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#why-perform-meta-analysis",
    "href": "wiki-content/10-metaanalysis.html#why-perform-meta-analysis",
    "title": "Meta-Analysis",
    "section": "Why perform Meta-Analysis?",
    "text": "Why perform Meta-Analysis?\nMeta-analyses are performed for a variety of reasons:\n\nTo provide a test with more power than separate studies\nTo provide an improvement in statistical precision\nTo summarise numerous and inconsistent findings\nTo investigate consistency of effect across different samples\n\n(Reference: Cochrane Handbook)\nTo understand the basics and for exact equations, keep reading.\nEquations shown below are from the following references, where more information can be found:\n\nVesterinen et al, 2014. “Meta-analysis of data from animal studies: a practical guide.” Journal of neuroscience methods\nBorenstein et al., 2009. Introduction to Meta-Analysis",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#meta-analysis-tools",
    "href": "wiki-content/10-metaanalysis.html#meta-analysis-tools",
    "title": "Meta-Analysis",
    "section": "Meta-Analysis Tools",
    "text": "Meta-Analysis Tools\nLuckily, statistical software takes care on most of the ‘heavy lifting’ when it comes to calculating effect sizes, pooling them, and making forest plots. There are different tools available to perform meta-analysis.\nR is the recommended software as it is free and open source and supports transparent documentation of meta-analysis steps. To read more about R and download it for free, see the R Project website here. If this is your first time conducting a meta-analysis using R, you can practice with our meta-analysis tutorial, read more in section 15.2.\nOther tools include:\n\nStata\nComprehensive Meta-Analysis\nRevMan",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#step-1.-calculate-effect-size",
    "href": "wiki-content/10-metaanalysis.html#step-1.-calculate-effect-size",
    "title": "Meta-Analysis",
    "section": "Step 1. Calculate effect size",
    "text": "Step 1. Calculate effect size\nThe first step is to calculate the effect size for each outcome within each study. Your outcomes may be:\n\nContinuous\nDichotomous\n\n\nContinuous\nFor continuous outcomes, commonly used effect size measures include:\n\nMean Difference\nNormalised Mean Difference\nStandardised Mean Difference\n\n\nMean Difference\nMean Difference: Raw mean difference can be used when the outcomes are reported on a meaningful scale and all studies in the analysis use the same scale. The meta-analysis is performed directly on the raw difference in means.\nMean Difference Effect Size: \\[ ES_i = \\bar{x}_c - \\bar{x}_\\text{rx}\\]\nStandard Error: \\[ SE_i = \\sqrt{\\frac {N}{n_{\\text{rx}} \\times n'_c} \\times S_{\\text{pooled}}^2} \\]\nwhere \\(S_{\\text{pooled}}\\) is: \\[S_{\\text{pooled}} = \\sqrt \\frac {(n'_c - 1)SD_c^2 + (n_{\\text{rx}} - 1)SD_{\\text{rx}}^2}{N -2} \\]\n\n\nNormalised Mean Difference\nNormalised Mean Difference: Normalised mean difference (NMD) can be used when outcomes are on a ratio scale, where the score on a ‘control’ or ‘sham’ animal is known. The most common method to calculate NMD is as a proportion of the mean.\nThe effect size calculation for normalised mean difference:\n\\[ES_i= 100 \\times  \\frac {(\\bar{x}_c - \\bar{x}_\\text{sham}) - (\\bar{x}_\\text{rx} - \\bar{x}_\\text{sham})}{\\bar{x}_c - \\bar{x}_\\text{sham}}\\] where \\(\\bar{x}_\\text{sham}\\) is the mean score for the unlesioned/normal/untreated animal.\nThe standard deviation calculations are as follows: \\[SD_\\text{c*} = 100 \\times \\frac {SD_c}{\\bar{x}_c - \\bar{x}_\\text{sham}}\\] and \\[SD_\\text{rx*} = 100 \\times \\frac {SD_\\text{rx}}{\\bar{x}_\\text{c} - \\bar{x}_\\text{sham}}\\]\n\\[ES_i= 100 \\times  \\frac {(\\bar{x_c} - \\bar{x_\\text{sham}}) - (\\bar{x_\\text{rx}} - \\bar{x_\\text{sham}})}{\\bar{x_c} - \\bar{x_\\text{sham}}} \\] where \\[\\bar{x_\\text{sham}} \\] is the mean score for the unlesioned/normal/untreated animal.\nThe standard deviation calculations are as follows: \\[SD_c* = 100 \\times \\frac {SD_c}{\\bar{x_c} - \\bar{x_\\text{sham}}}\\] and \\[SD_\\text{rx*} = 100 \\times \\frac {SD_\\text{rx}}{\\bar{x_\\text{rx}} - \\bar{x_\\text{sham}}}\\]\nStandard error of the effect size is: \\[SE_i = \\sqrt{ \\frac{SD_\\text{c*}^2}{n'_c} + \\frac {SD_{rx*}^2}{n_{rx*}} }\\]\n\n\nStandardised Mean Difference\nStandardised Mean Difference: (SMD), Cohen’s d and Hedge’s g. SMD is used when the scale of measurement differs across studies and it is not meaningful to combine raw mean differences. The mean difference in each study is divided by the study’s standard division to create an index comparable across studies.\nHedge’s G SMD Effect Size: \\[ES_i = \\frac {\\bar{x}_c - \\bar{x}_\\text{rx}}{S_{\\text{pooled}}} \\times (1 - \\frac{3}{4N - 9})  \\] And standard error of the effect size is: \\[ SE_i = \\sqrt{ \\frac{N}{n_{\\text{rx}} \\times n'_c} + \\frac{ES_i^2}{2(N - 3.49)} }\\]\n\n\n\nDichotomous Outcomes\nFor dichotomous outcomes the most commonly used effect size measures for animal studies is odds ratio.\n\nOdds Ratio\nOdds Ratio: For event data. The ratio of number of events to the number of non-events. It represents the odds that an outcome will occur given a particular exposure, compared to the odds of the outcome occurring without that exposure.\nOdds Ratio Effect Size \\[ OR_i = \\frac {a_i \\times d_i}{b_i \\times c_i}  \\]\nwith the standard error of the odds ratio effect size: \\[ SE(ln(OR_i)) = \\sqrt{ (1/a_i)+(1/b_i)+(1/c_i)+(1/d_i) }   \\]\nIn the meta-analysis of events, we might encounter a scenario where not a single event occured, in one or more groups. This is particularly likely with the small samples in preclinical research. In the case of zero events, the OR is mathematically ill defined. Two remedies exist: 1) adding 0.5 to all zero frequencies to study-specific 2x2 tables (Weber et al., 2020), or the preferred method, 2) to use the arcsine transformation of the frequencies.\n\\[ arcsin \\sqrt (a/a+b) - arcsin \\sqrt(c/c+d) \\]\nWhile the arcsine difference is prefered from a mathematical point of view (Rücker et al. 2008), the transformation leads to an abstract effect size that cannot be as readily interpreted as an OR. This transformation is thus recommended for determining statistical significance.\nYou might come across Risk Ratio (or Relative Risk), the risk of an event in one group (e.g., exposed group) versus the risk of the event in the other group (e.g., non-exposed group), or Hazard Ratio, however these data are rarely seen in primary animal experiments. For more information of Risk Ratio in clinical systematic reviews, see the Cochrane Handbook.\n\n\n\nMedian\nMedian Survival or time to event data. The effect is calculated by dividing the median survival in the treatment group b the median in the control group, and the logarithm of that is taken. Read more about median survival here.\n\\[ ES_i = log (\\frac{Median_{\\rm rx}}{Median_c} ) \\]\n\n\nTrue number of Controls\nA single experiment can contain a number of comparisons. If the control cohort is serving more than one treatment group, we correct the number of animals reported in the control cohort by the number of treatment groups.\n\nTrue number of controls \\[n'_c = \\frac{n_c}{{\\rm num. treatment groups}}\\]\nTrue N for each comparison \\[N = n_{\\text{rx}} + n'_c\\]\nConverting SEM to SD \\[ SD_c = SEM_c \\times \\sqrt n_c \\] and \\[SD_{\\text{rx}} = SEM_{\\text{rx}} \\times \\sqrt n_{\\text{rx}} \\]",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#step-2.-combine-effect-sizes",
    "href": "wiki-content/10-metaanalysis.html#step-2.-combine-effect-sizes",
    "title": "Meta-Analysis",
    "section": "Step 2. Combine effect sizes",
    "text": "Step 2. Combine effect sizes\nThe next step is to combine the effect sizes for each comparison together in a meta-analysis model.\nBefore you pool your effect sizes, you may conisder:\nWeighting Effect Sizes: In meta-analysis it is usual to attribute different weights to each study in order to reflect relative contributions of individual studies to the total effect size. In animal study meta-analysis we weight the studies according to precision. More precise studies are given greater weight in the calculation of the effect size. We recommend using the inverse variance method, where individual effect sizes are multiplied by the inverse of their squared standard error:\n\\[W_i = \\frac{1}{SE^2_i} \\] Where \\[{SE^2_i}\\] is the square standard error of the effect size calculated.\nThis gives the weighted effect size of: \\[W_iES_i = ES_i \\times \\frac{1}{SE^2_i} \\]\nNesting Effects: Where several outcomes are reported and it is appropriate to combine them into a single statistic, we can “nest” outcomes. To do this we take each outcome, weight it by multiplication by the inverse of the variance for that outcome, sum these weighted values for all outcomes and divide by the sum of the weights.\n\\[ES_{\\theta\\text{i}} = \\frac{\\sum_{i=1}^{k} W_iES_i}{\\sum_{i=1}^{k} W_i} \\] Where \\[W_i\\] is the measure of weight (e.g. inverse variance). \\[W_iES_i \\] is the weighted effect size, and k denotes the total number of studies included in the meta-analysis.\nThe standard error is calculated: \\[SE_{\\theta\\text{i}} = \\sqrt \\frac{N_{comparisons}}{\\sum_{i=1}^{k} W_i} \\]\nPooling Effect Sizes\nThere are two commonly used models for pooling effect sizes:\n\nFixed Effect Model\nRandom Effects Model\n\nThe selection of which model to use should be stated in your protocol with a priori. The decision is based on the nature of the studies likely to be included in your review. Random effects model is most commonly used in preclinical studies as we usually synthesise data from studies performed in different laboratories and we expect heterogeneity. We often synthesise data from experiments where the species, age, or sex of the animals are different, the intervention may be given at varying doses or at different times in relation to the outcome. We assume that these study design variables have an impact on the effects we see in studies.\nRarely, when doing a systematic review of data from one specific laboratory, if all the studies in your meta-analysis were conducted using the same model induction, paradigms, and interventions, you may consider a fixed effect model (Borenstein et al., 2009).\n\nFixed Effects Model\nUnder the fixed effect model we assume that there is one true effect size which is shared by all the included studies. It follows that the combined effect (global estimate) is our estimate of this common effect size.\n\n\n\n\n\n\n\nRandom Effects Model\n\nUnder the random effects model we allow that the true effect could vary from study to study. E.g. the effect size might be a little higher if the patients are older; in rats vs. mice; if the study used a slightly more intensive or longer variant of the intervention etc.\nThe studies included in the meta-analysis are assumed to be a random sample of the relevant distribution of effects, and the combined effect estimates the mean effect in this distribution.",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#step-3.-investigate-heterogeneity",
    "href": "wiki-content/10-metaanalysis.html#step-3.-investigate-heterogeneity",
    "title": "Meta-Analysis",
    "section": "Step 3. Investigate heterogeneity",
    "text": "Step 3. Investigate heterogeneity\nThe third step is to investigate potential sources of heterogeneity (pre-specified in your protocol). Heterogeneity is the variability between groups of studies caused by differences in:\n\nstudy samples (e.g. species, sex)\ninterventions of outcomes (e.g. dose, outcome measure type)\nmethodology (e.g. design, quality)\n\nChi-squared \\(\\chi^2\\) (or Chi2) assess whether observed differences in results are compatible with chance alone. I2 describes the percentage of variability in effect estimates that is due to heterogeneity rather than sampling error or chance along.\nYou can investigate heterogeneity using:\n\nSub-group analysis. Read more about sub-group analysis here.\nMeta-regression model. Read more about meta-regression here.",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#step-4.-reporting-biases",
    "href": "wiki-content/10-metaanalysis.html#step-4.-reporting-biases",
    "title": "Meta-Analysis",
    "section": "Step 4. Reporting biases",
    "text": "Step 4. Reporting biases\nPublication Bias occurs when the results of published and unpublished studies differ systematically. Unfortunately, neutral and negative studies take longer to be published, remain unpublished, are less likely to be identified in systematic review, and this can lead to an overstatement of efficacy in meta-analysis.\nThere are also other biases that may effect your systematic review including, selective outcome reporting and selective analysis reporting.\nWe can test for potential publication bias in our data plotting our data on a funnel plot. The outer dashed lines indicate the triangular region within which 95% of studies are expected to lie, in the absence of both biases and heterogeneity. The solid vertical line refers to the line of no effect. Image from Sterne et al., 2011\n\n\n\nIf you do observe asymmetry in your funnel plot, there may be a number of sources:\n\nReporting Biases\n\nPublication bias\nSelective outcome reporting\nSelective analysis reporting\n\nPoor methodological quality (leading to inflated effects in smaller studies)\n\nPoor methodological design\nInadequate analysis\nFraud\n\nTrue heterogeneity: Effect size differs according to study size due to e.g. differences in the intensity of interventions, or in underlying risk between studies with different sizes.\nArtefacts: Sampling variation can lead to an association between the intervention effect and its standard error.\nChance: Asymmetry may occur by change - motivating the use of statistical asymmetry tests.",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/10-metaanalysis.html#step-5.-interpret-the-results",
    "href": "wiki-content/10-metaanalysis.html#step-5.-interpret-the-results",
    "title": "Meta-Analysis",
    "section": "Step 5. Interpret the results",
    "text": "Step 5. Interpret the results\nThe forest plot or timber plot is the main graphical output or representation from a meta-analysis.\nReading and understanding these plots will allow you to understand the findings from a meta-analysis. Meta-analyses of animal studies tend to include many studies with small sample sizes. Therefore, it is common to see preclinical meta-analyses graphically represented with a timber plot, a slight variation on the forest plot.\nHere is an example of a timber plot. In this meta-analysis the research question was: What is the effect of antidepressants compared vehicle or no treatment on infarct volume in animal models of ischaemic stroke? McCann et al., 2014\n\n\n\nOutcome: A meta-analysis is conducted on a single outcome of interest at a time. The outcome of interest in this meta-analysis is Reduction in Infarct Volume, as displayed on the y-axis label.\nIndividual Study Effects: In this meta-analysis there were 58 experiments included. Each black dot represents the effect size reported in a single experiment, the difference in outcome between the mean and the control group. Each black dot has thin black lines above and below the effect size, these represent the errors bars associated with the effect size reported. Individual study effect sizes are displayed in order of smallest to largest to highlight variation or heterogeneity in the literature.\nPooled Effect: Here, the gray bar behind the black dots represents the combined or pooled effect size across all included experiments and its confidence intervals. In this example, the effect size is 27.3% (95% CI, 20.7%–33.8%).\nClinical Forest Plots: A step-by-step guide to interpreting a forest plot from a typical clinical meta-analysis is available here.",
    "crumbs": [
      "Meta-Analysis"
    ]
  },
  {
    "objectID": "wiki-content/08-dataextraction.html",
    "href": "wiki-content/08-dataextraction.html",
    "title": "Data Extraction",
    "section": "",
    "text": "The data you extract from each included study should be pre-specificed in your systematic review protocol. It is best practice to extract data in duplicate, two independent reviewers, to prevent errors.",
    "crumbs": [
      "Data Extraction"
    ]
  },
  {
    "objectID": "wiki-content/08-dataextraction.html#study-characteristics",
    "href": "wiki-content/08-dataextraction.html#study-characteristics",
    "title": "Data Extraction",
    "section": "Study characteristics",
    "text": "Study characteristics\nStudy characteristics to extract from included articles may include:\n\nPICO information (e.g. age and sex of population, species and strain of animal, dose and timing of intervention, type and time of outcome assessment)\nStudy Design information\nStudy Quality information (see below)\nAdditional information (e.g. time between intervention and outcome assessment, any comorbidity information)",
    "crumbs": [
      "Data Extraction"
    ]
  },
  {
    "objectID": "wiki-content/08-dataextraction.html#quantitative-data",
    "href": "wiki-content/08-dataextraction.html#quantitative-data",
    "title": "Data Extraction",
    "section": "Quantitative data",
    "text": "Quantitative data\nExtracting quantitative and numerical data from included studies is necessary to perform meta-analysis to pool the effect sizes from.\nYour outcomes of interest may be:\n\nDichotomous (e.g. mortality, tumour presence) \nContinuous (e.g. blood pressure, or weight loss) \nCount Data (e.g. number of events)\n\nData about your outcomes may be provided in various formats including:\n\nIn tables\nIn text\nIn graphs\n\nYou may need to use tools such as Adobe desktop ruler or WebPlotDigitizer to extract numerical values (e.g. means and standard deviations (SD) or standard error of the mean (SEM) from graphs). Some studies may report values on a different scale. Be aware, you may need to convert these to a scale that is common across all studies (e.g. log scale conversion).\nIn some cases it might not be clear if authors reported SEM or SD as a measure of variance. We recommend extracting the value as SEM as this is considered to be a more conservative approach from a meta-analysis perspective (assuming that the value of SD can only be larger).",
    "crumbs": [
      "Data Extraction"
    ]
  },
  {
    "objectID": "wiki-content/08-dataextraction.html#data-extraction-software",
    "href": "wiki-content/08-dataextraction.html#data-extraction-software",
    "title": "Data Extraction",
    "section": "Data extraction software",
    "text": "Data extraction software\nAs you are extracting these pieces of information you will want to store them in the same place for easier, later synthesis and analysis.\nWe recommend using SyRF the Systematic Review Facility to extract and store your data. It is a free-to-use online platform where you can create custom data extraction forms for your review. Flexible questions types and question settings, as well as online format allow for easy data extraction for you and your review team to simultaneous extract data from included papers. For more information see the SyRF Website and the SyRF Help Guide to set up your free review project.",
    "crumbs": [
      "Data Extraction"
    ]
  },
  {
    "objectID": "wiki-content/06-systematicsearch.html",
    "href": "wiki-content/06-systematicsearch.html",
    "title": "Systematic Search",
    "section": "",
    "text": "To identify relevant studies to include in your SR, you need to perform a comprehensive literature search based on a well-designed search strategy.",
    "crumbs": [
      "Systematic Search"
    ]
  },
  {
    "objectID": "wiki-content/06-systematicsearch.html#selecting-databases",
    "href": "wiki-content/06-systematicsearch.html#selecting-databases",
    "title": "Systematic Search",
    "section": "Selecting databases",
    "text": "Selecting databases\nBibliographic databases differ in their coverage of journals and indexing of articles, so to ensure your research is systematic, you will have to search multiple databases.\nWhich databases you search will depend on your research area and question. For preclinical research, typical databases include:\n\nPubMed\nEmbase\nWeb of Science\n\nA librarian or an expert in bibliographic databases will be able to help you identify other potential databases and construct database-specific search terms.\nOn top of electronic databases, you might want to use other methods to find relevant papers such as: scanning reference lists of relevant studies (both primary studies and reviews), hand searching key journals, contacting experts in the field, and searching additional relevant internet resources. Keep a record of alternative methods used and the data collected in a structured format.\n\nPubMed\nPubMed is a bibliographic database comprising of more than 30 million citations for biomedical literature from MEDLINE, life science journals, and online books.\nIt is a free resource that supports the search and retrieval of biomedical and life sciences literature with the aim of improving health, and is maintained by the National Center for Biotechnology Information (NCBI) at the US National Library of Medicine.\nLinks & Resources:\n\nThe PubMed Advanced Search Builder is a useful tool to build your search query.\nInformation on MeSH Headings.\n\n\n\nEmbase\nEmbase is a biomedical research database covering literature from 1947 to present day. It indexes over 32 million records, including MEDLINE titles, as well as articles from 2,900 journals unique to Embase.\nYou may access Embase directly or through Ovid depending on your library subscription.\nLinks & Resources:\n\nEmbase indexing and EmTree Headings\n\n\n\nWeb of Science\nWeb of Science is a publisher-independent citation database. The Web of Science Core Collection indexes scholarly journals, books, and proceedings in the sciences, social sciences, and arts and humanities and can be used to navigate the full citation network.\nWeb of Science can also be used to search other databases including SciELO, KCI-Korean Journal Database and Zoological Record.\n\n\nOther sources & grey literature\nOther bibliographic databases include:\n\nCochrane Central Register of Controlled Trials (CENTRAL)\nGoogle Scholar\nScopus\nCumulative Index to Nursing and Allied Health Literature (CINAHL)\nPsycINFO\n\nAccess may vary depending on institutional access. Document your search strategy so it is sufficiently reproducible.",
    "crumbs": [
      "Systematic Search"
    ]
  },
  {
    "objectID": "wiki-content/06-systematicsearch.html#search-strategy-development",
    "href": "wiki-content/06-systematicsearch.html#search-strategy-development",
    "title": "Systematic Search",
    "section": "Search strategy development",
    "text": "Search strategy development\nSelect your search terms based around each of the PICO (or equivalent) concepts in your research question.\n\nStep 1: Find keywords and synonyms for each element\nA good exercise is to think of as many synonyms as possible for each of your main concepts or PICO elements.\nFor example:\nIf your research question is: What is the effect of antidepressants compared to vehicle or no treatment on infarct volume in animal models of stroke?\n\n(P)opulation: Stroke. Synonyms might include: cerebral ischaemia, cerebrovascular accident.\n(I)ntervention: Antidepressants. Synonyms might include: fluoxetine, SSRIs\n\n\n\nStep 2: Index/subject terms (database-specific)\nEach core database has their own system for indexing terms, topics, and subjects. Check what subject headings and indexing terms the databases you are interested in searching before you start.\n\nMeSH terms (PubMed)\nEmtree terms (Embase) (See more information about MeSH and EMTREE above Selecting Databases\n\nWhy use both keywords and indexed terms in your search strategy?\nArticles in PubMed are manually indexed but there is usually a slight delay. To capture all articles that use non-standard language, including recently published ones, you might miss some by using only a keyword search.\n\n\nStep 3: Combining search terms using Boolean operators\nBoolean operators include:\n\nAND\nOR\nNOT\n\nThe OR operator is used to connect two or more similar concepts (synonyms). It is used to broaden the results by telling the database that at least one of the search terms must be present in the results.\nThe AND operator is used to narrow the results. It is used to tell the database that all search terms must be present in each result.\n \n\n\nPrecision & sensitivity\nA good search strategy aims to to maximise sensitivity while attempting to maximise precision.\n\nPrecision is the ability of search strategy to exclude irrelevant articles.\nSensitivity is the ability of a search strategy to identify all relevant articles.\n\n\n\nTips & tricks\n\nConsider differences in spelling (e.g. US vs UK English)\nConsider using other PubMed fields e.g. MeSH SubHeadings [SH], or Pharmacological Action [PA]. Find more information here: PubMed Search Tags\nWhen using the NOT Boolean Operator, consider what relevant literature you might be excluding\nConsider truncation symbols or “wildcards” for your search (e.g. ischem* for ischemia and ischemic, etc). Check all bibliographic databases allow this before adding to your search\nThe Polyglot Search Translator is a tool that will assist you in translating the syntax of your search string across various databases. For more information of the Polyglot Search Translator see here\n\n\n\nConsulting an Information Specialist\nWhen developing a systematic search strategy, it is useful to consult an information specialist to make your search as precise and exhaustive as possible. Before contacting an information specialist, there are a couple of things to consider:  - Make sure you have your research question clearly defined e.g., in a PICO format.  - To provide them with more context on the aims of your review, be sure to include a couple of representative publications that you would include in your review.  - Where possible, share a draft of your SR protocol and search strategy with them",
    "crumbs": [
      "Systematic Search"
    ]
  },
  {
    "objectID": "wiki-content/06-systematicsearch.html#combine-search-results",
    "href": "wiki-content/06-systematicsearch.html#combine-search-results",
    "title": "Systematic Search",
    "section": "Combine search results",
    "text": "Combine search results\nOnce you have run your searches across multiple databases, you can combine your search results in a reference manager software, such as EndNote or Zotero.\nTo more easily find full text pdfs, remember to add you library subscription information into the settings or preferences of the reference manager, e.g. EzProxy information or OpenURL information.\n\nDoes the import order matter? YES!\nThe order that you import your references into Endnote or another reference manager matters. Different bibliographic databases have different quality or completeness of the references you are interested in, and reference managers use this information to deduplicate the results (the next step).\nThe recommended order is:\n\nMedline\nEmbase\nMedline in process (if included)\nOther databases from OvidSP (PsycInfo, EconLit etc)\nPubMed\nCinahl Plus\nOther databases from Ebsco\nWeb of Science databases\nScopus\nProQuest databases\nCochrane databases\nCRD databases\nAny other databases\nClinical Trials websites",
    "crumbs": [
      "Systematic Search"
    ]
  },
  {
    "objectID": "wiki-content/06-systematicsearch.html#deduplication",
    "href": "wiki-content/06-systematicsearch.html#deduplication",
    "title": "Systematic Search",
    "section": "Deduplication",
    "text": "Deduplication\nAs you have searched several different databases and other sources, there are likely duplicates or overlap. Time spent deduplicating your reference library will ensure you have accurate numbers (total records/included/excluded) to report and don’t waste your time screening duplicates.\nTools to help remove duplicate references include:\n\nEndnote can be used to find and remove duplicate records. See this resource.\nStand-alone tools such as the SR-Accelerator Tool and the ASySD tool for preclinical reviews.",
    "crumbs": [
      "Systematic Search"
    ]
  },
  {
    "objectID": "wiki-content/06-systematicsearch.html#searching-tools",
    "href": "wiki-content/06-systematicsearch.html#searching-tools",
    "title": "Systematic Search",
    "section": "Searching tools",
    "text": "Searching tools\nThe Polyglot Search Translator is a tool that will assist you in translating the syntax of your search string across various databases. For more information of the Polyglot Search Translator see here. Please not this cannot be used as a simple translator without adequate review of the translation and thorough testing of the search.",
    "crumbs": [
      "Systematic Search"
    ]
  },
  {
    "objectID": "wiki-content/06-systematicsearch.html#find-retrieve-full-texts",
    "href": "wiki-content/06-systematicsearch.html#find-retrieve-full-texts",
    "title": "Systematic Search",
    "section": "Find & retrieve full texts",
    "text": "Find & retrieve full texts\nOnce you have your library of unique references you can find and retrieve the full texts.\n\nUse your reference manager. Guides for retrieving from Endnote and Zotero can be found at the respective links.\nSearch Online: Google search, GoogleScholar, ResearchGate, etc.\nContact corresponding authors directly via email or Twitter.\nLast resort: ask your librarian to assist with inter-library loans. (NB: these can be very costly!)\n\n\nTips & tricks for full text retrieval\n\nAdd your Institutional Log-in information to the settings or preferences of the reference manager, e.g. EzProxy information or OpenURL information, so you can more easily find the full texts that your institutional library has access to.\nBe careful using custom scripts or other programs to bulk download as this can result in your institutional IP address being blocked\nIf your search strategy has retrieved a lot of potentially relevant results, you may want to consider waiting to find the full texts until after you have carried out titles and abstract screening (see below). This will greatly reduce the number of full text records you need to find, and you will not waste time trying to find articles that are not relevant to your research question.",
    "crumbs": [
      "Systematic Search"
    ]
  },
  {
    "objectID": "wiki-content/04-researchquestion.html",
    "href": "wiki-content/04-researchquestion.html",
    "title": "Research Question",
    "section": "",
    "text": "All systematic reviews start with a strong, concise research question. This serves as the back-bone for a good search strategy, as it determines the structure and sequence for your literature searches.",
    "crumbs": [
      "Research Question"
    ]
  },
  {
    "objectID": "wiki-content/04-researchquestion.html#pico-peco",
    "href": "wiki-content/04-researchquestion.html#pico-peco",
    "title": "Research Question",
    "section": "PICO & PECO",
    "text": "PICO & PECO\nCommonly preclinical SR research questions follow a PICO or PECO stucture:\n\n(P)opulation, (P)articipants, or (P)roblem: What are the characteristics of the population or participants (species, sex, developmental stage, risk factors, or for human participants demographics, pre-existing conditions, etc)? What is the condition or disease of interest?\n(I)ntervention or (E)xposure: What is the intervention or exposure under consideration for this population?\n(C)omparison: What is the alternative to the intervention (e.g. placebo, different drug, surgery)?\n(O)utcome: What are the relevant outcomes (e.g. quality of life, change in clinical status, morbidity, adverse effects, complications)?\n\nThere are other research question structures depending on your area or topic of interest, for example, diagnostic test reviews, and prognostic reviews. For more information, see this article on Formulating Review Questions.",
    "crumbs": [
      "Research Question"
    ]
  },
  {
    "objectID": "wiki-content/04-researchquestion.html#stakeholders",
    "href": "wiki-content/04-researchquestion.html#stakeholders",
    "title": "Research Question",
    "section": "Stakeholders",
    "text": "Stakeholders\nIt is important that you engage stakeholders early on in the review phase to ensure the research question and findings from the review are relevant. Consider the following:\n\nWho will use the results of your systematic review?\nFrom their perspective, what are the relevant questions to ask?",
    "crumbs": [
      "Research Question"
    ]
  },
  {
    "objectID": "wiki-content/04-researchquestion.html#preclinical-examples",
    "href": "wiki-content/04-researchquestion.html#preclinical-examples",
    "title": "Research Question",
    "section": "Preclinical examples",
    "text": "Preclinical examples\nFor reference, see examples of research questions for published reviews.\n“What is the effect of antidepressants compared to vehicle or no treatment on infarct volume in animal models of ischaemic stroke?”\n\nP - Animal models of ischaemic stroke\nI - Antidepressants\nC - Vehicle or no treatment\nO - Infarct volume",
    "crumbs": [
      "Research Question"
    ]
  },
  {
    "objectID": "wiki-content/02-srs-3rs.html",
    "href": "wiki-content/02-srs-3rs.html",
    "title": "Systematic Reviews & 3Rs",
    "section": "",
    "text": "The principles of the 3Rs (Replacement, Reduction, and Refinement) are a framework for humane animal research. Systematic review is a valuable tool for advancing the 3Rs, primarily through the reduction and refinement of animal use in research. Using existing animal data, systematic reviews can contribute to improvements in animal studies including:\nFor more examples of systematic reviews which implement 3Rs and animal welfare, please see Ritskes-Hoitinga & van Luijk, 2019.",
    "crumbs": [
      "Systematic Reviews & 3Rs"
    ]
  },
  {
    "objectID": "wiki-content/02-srs-3rs.html#arrive-guidelines",
    "href": "wiki-content/02-srs-3rs.html#arrive-guidelines",
    "title": "Systematic Reviews & 3Rs",
    "section": "ARRIVE Guidelines",
    "text": "ARRIVE Guidelines\nThe Guidelines for Reporting Primary Animal Research are: ARRIVE 2.0",
    "crumbs": [
      "Systematic Reviews & 3Rs"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CAMARADES Systematic Review Wiki",
    "section": "",
    "text": "CAMARADES guides you step-by-step—from defining your question to extracting data.\n\n\nWhat is a preclinical review?\nLearn more →\n\n\n\nFollow protocol, search, screen, and analyze.\nLearn more →\n\n\n\nDownload forms, scripts, and checklists.\nLearn more →"
  },
  {
    "objectID": "index.html#explore-the-wiki",
    "href": "index.html#explore-the-wiki",
    "title": "CAMARADES Systematic Review Wiki",
    "section": "Explore the Wiki",
    "text": "Explore the Wiki\nGot questions? Email us."
  },
  {
    "objectID": "14-workshops.html",
    "href": "14-workshops.html",
    "title": "Workshops",
    "section": "",
    "text": "We offer a range of workshops on Systematic Review and Meta-Analysis of Animal Studies.\nIntroduction to Systematic Review & Meta-Analysis of Animal Studies  Through a mix of lectures and hands-on practical activities and tutorials across 3 half days, you will learn the major steps required to undertake a systematic review and meta-analysis of preclinical animal studies. For information on our next workshop and to register, please click here: Introduction to Systematic Review & Meta-Analysis of Animal Studies  We have summarized the main points of the workshop in this Cheat sheet\nProtocol Development for Systematic Review of Animal Studies  This workshop will cover the contents of a transparent and comprehensive preclinical systematic review protocol. It will cover the rationale behind registering your systematic review protocol and where to register. This workshop is aimed at researchers who already have a basic understanding of systematic reviews of animal data. For more information, please click here: Protocol Development for Systematic Review of Animal Studies\nCritical Appraisal of Animal Studies  This interactive practical workshop will explore study quality and risks of bias, internal and external validity, in scientific publications of animal experiments. Participants will gain hands-on experience critically appraising published animal experiments. For more information, please click here: Critical Appraisal of Animal Studies"
  },
  {
    "objectID": "14-workshops.html#elearning",
    "href": "14-workshops.html#elearning",
    "title": "Workshops",
    "section": "eLearning",
    "text": "eLearning\nYou can also learn about Systematic Review and Meta-Analysis of Animal Studies at your own pace by taking our eLearning course. Take a single module or multiple modules to suit your needs. Each module consists of a combination of self-paced presentations and interactive activities and quizzes, allowing you to go over the materials as many times as you need. Exercises and activites are designed to test your understanding of the materials covered.\nWe currently have modules on the following topics:\n\nIntroduction to Systematic Review & Meta-Analysis of Animal Studies\nSystematic Literature Searching\nDefining a research question\nProtocol Development\nCitation Screening & Eligibility Criteria\nCritical Appraisal of Animal Studies\nData Extraction\nMeta-Analysis of Animal Studies\n\n\n–&gt; Take me to the eLearning platform!\n\n\nIf you have any questions about the eLearning platform or encounter any technical difficulties, please contact us at camarades.berlin@charite.de"
  },
  {
    "objectID": "14-workshops.html#meta-analysis-tutorial",
    "href": "14-workshops.html#meta-analysis-tutorial",
    "title": "Workshops",
    "section": "Meta-Analysis Tutorial",
    "text": "Meta-Analysis Tutorial\n We have created a web-based tutorial to complement the workshop: Introduction to Systematic Review & Meta-Analysis of Animal Studies\nThe web-based app uses R programming language to work through a meta-analysis of animal data but you do not need any previous experience with R to complete the tutorial. \n\n&gt;&gt;&gt; Click here to launch the tutorial\n\nThe tutorial uses examples data from the publication:\n\n\nMcCann SK, Cramond F, Macleod MR et al. Systematic Review and Meta-Analysis of the Efficacy of Interleukin-1 Receptor Antagonist in Animal Models of Stroke: an Update. Translational Stroke Research 7, 395–406 (2016)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We have put together this Wiki Page to provide information and documents, links, and useful tools to guide your through your preclinical systematic review. These resources have been put together using many CC-BY-4.0 sources including; SyRF, and Cochrane Interactive Learning. We thank these organisations and teams for making their resources available, definitely check out their resources as well!\nThis resource was last updated on:\n[1] \"04 August, 2025\""
  },
  {
    "objectID": "about.html#to-cite-this-resource",
    "href": "about.html#to-cite-this-resource",
    "title": "About",
    "section": "To cite this resource",
    "text": "To cite this resource\nPreclinical Systematic Reviews & Meta-Analysis Wiki, (August, 2025), CAMARADES Berlin, QUEST-BIH Charité. Accessed from: https://www.CAMARADES.de"
  },
  {
    "objectID": "about.html#acknowledge-our-services",
    "href": "about.html#acknowledge-our-services",
    "title": "About",
    "section": "Acknowledge our services",
    "text": "Acknowledge our services\nAt CAMARADES we provide services to support researchers in conducting high-quality systematic reviews of preclinical evidence. Engaging with our support services can take many forms, from attending our drop-in sessions, email consultation, to one-on-one sessions for the duration of your project. Each project team and review topic is unique, and the level of support required can vary across the life-cycle of your project.\nAs our services are free of charge, we greatly appreciate appropriate acknowledgement of our support in your published work.\nIf you have utilised our support services, we would be grateful for acknowledgment in your published work. For example, “We would like to thank [insert team member’s name] from CAMARADES Berlin, QUEST Center, Berlin Institute of Health @ Charité Universitätsmedizin for consultation [and/or support].”\nFor more extensive support, which may span multiple stages of the project or forms of support, we typically join the review team as a co-author, given our assistance meets the criteria for authorship according to the ICMJE recommendations (see more below). In this case, potential authorship will be based on discussion and informed by the published guidance, according to the individual circumstances of the project.\nYour acknowledgement is essential to help us continue offering our services to the research community. We value your collaboration!\nThe ICMJE recommends that authorship be based on the following 4 criteria:\n\nSubstantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND\nDrafting the work or reviewing it critically for important intellectual content; AND\nFinal approval of the version to be published; AND\nAgreement to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved."
  },
  {
    "objectID": "about.html#join-the-systematic-review-community",
    "href": "about.html#join-the-systematic-review-community",
    "title": "About",
    "section": "Join the Systematic Review Community",
    "text": "Join the Systematic Review Community\nCOReS is a project to build a community around preclinical evidence synthesis. The project aims to bring together primary researchers and evidence synthesists to form communities and providing infrastructure and support systems to empower the community in the performance of systematic reviews in a collaborative manner. Join the community to improve the quality and value of preclinical research in biomedicine!  + Check out resources and practices for synthesisable animal research on the COReS Hub.\n+ Stay up-to-date with Community News via the newsletter. Sign up to the newsletter.\n+ Join the discussion forum to share ideas, work collaboratively, and connect with researchers and methodologists. Make a free user account for the discussion forum here.\n+ Follow the project on LinkedIn for regular update on education offers, talks, and project development. Check out COReS on LinkedIn here.\n Find our more about joining the community on the COReS Hub."
  },
  {
    "objectID": "about.html#our-team",
    "href": "about.html#our-team",
    "title": "About",
    "section": "Our Team",
    "text": "Our Team\n\nSarah McCann, PhD\nTorsten Rackoll, PhD\nAlexandra Bannach-Brown, PhD\nSofija Vojvodic, MSc\nFriederike Elisabeth Kors, PhD\nMaria Arroyo Araujo, PhD\nMaria Economou, PhD\nDaniel Schulze, PhD\n\n\nFor more information on our team and our services and projects, please see the BIH QUEST website.\n\nIf you have questions about the resources, or would like to ask a question about your specific review, get in touch: Email us here\nThis resource is supported by Charité 3Rs & VolkwagenStruftung.\n\n\n\n\nFor more information about 3Rs at Charité – Universitätsmedizin Berlin, visit the Charité 3Rs Toolbox.\n CAMARADES Berlin are located in the QUEST Center, Berlin Institute for Health\n\n\n\n  For more information about CAMARADES in Edinburgh, please click here."
  },
  {
    "objectID": "wiki-content/01-intro.html",
    "href": "wiki-content/01-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "A systematic review (SR) is a literature review that involves systematically locating, appraising, and synthesising evidence from scientific studies to answer a defined research question based on pre-specified criteria.\nThe methods of a systematic review (and meta-analysis) should be transparent and reproducible. This means that the methods are planned, conducted, and reported in a way that can be repeated by other research groups.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "wiki-content/01-intro.html#what-is-a-systematic-review",
    "href": "wiki-content/01-intro.html#what-is-a-systematic-review",
    "title": "Introduction",
    "section": "",
    "text": "A systematic review (SR) is a literature review that involves systematically locating, appraising, and synthesising evidence from scientific studies to answer a defined research question based on pre-specified criteria.\nThe methods of a systematic review (and meta-analysis) should be transparent and reproducible. This means that the methods are planned, conducted, and reported in a way that can be repeated by other research groups.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "wiki-content/01-intro.html#what-is-a-meta-analysis",
    "href": "wiki-content/01-intro.html#what-is-a-meta-analysis",
    "title": "Introduction",
    "section": "What is a meta-analysis?",
    "text": "What is a meta-analysis?\nA meta-analysis is a method of combining quantitative results from individual studies identified through systematic review in an overall statistical analysis.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "wiki-content/01-intro.html#clinical-preclinical-reviews",
    "href": "wiki-content/01-intro.html#clinical-preclinical-reviews",
    "title": "Introduction",
    "section": "Clinical & preclinical reviews",
    "text": "Clinical & preclinical reviews\nThere are many differences between preclinical and clinical systematic reviews, which is why we developed this Wiki, specific to preclinical systematic review methodology.\n\n\n\n\n\n\n\n\n\nPreclinical\nClinical\n\n\n\n\n# of included studies\nHigh\nLow\n\n\nSample size within studies\nLow\nHigh\n\n\nExperimental design\nVariable\nConsistent\n\n\nUses\n\nInvestigate translational failure\nExplore differences between studies (heterogeneity) e.g. internal & external validity\n\n\n\nInform future preclinical studies e.g. model selection\n\n\n\nInform early phase clinical trials\nExplain discrepancies in preclinical vs. clinical trial results\n\n\n\nInform 3Rs decisions\n\n\nExplore heterogeneity e.g. clinical populations\nInform later phase clinical studies\n\n\n\nInform clinical practice and guidelines",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "wiki-content/01-intro.html#why-perform-preclinical-srs",
    "href": "wiki-content/01-intro.html#why-perform-preclinical-srs",
    "title": "Introduction",
    "section": "Why perform preclinical SRs?",
    "text": "Why perform preclinical SRs?\nThere are many reasons to perform preclinical systematic reviews:\n\nTo summarise evidence from multiple similar studies to allow for more accurate estimates of effect\nThe methods used to find and select studies are transparent and reproducible, reducing bias and increasing the likeliness of producing reliable and accurate conclusions.\nSummarise findings from all available studies making information easier for the end-user to read and understand\nAnalyse individual study quality to inform confidence in the results\nQuantitative synthesis of results (meta-analysis)\nAllow for evidence-based inferences\n\n\n\n\n\nThe results of preclinical systematic reviews can:\n\nProvide evidence to change research practice by identifying risks of bias in preclinical experiments\nInfluence development of reporting guidelines and editorial policies\nProvide evidence to support reporting of positive, negative and neutral results through detection of publication bias\nIdentify study design features that compromise potential clinical application\nContribute to evidence-based clinical trial design",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "wiki-content/03-b4ustart.html",
    "href": "wiki-content/03-b4ustart.html",
    "title": "Before You Start",
    "section": "",
    "text": "There are a couple of things to check before you start your SR. Read more below.",
    "crumbs": [
      "Before You Start"
    ]
  },
  {
    "objectID": "wiki-content/03-b4ustart.html#is-it-necessary",
    "href": "wiki-content/03-b4ustart.html#is-it-necessary",
    "title": "Before You Start",
    "section": "Is it necessary?",
    "text": "Is it necessary?\nConsider the following before starting your SR:\n\nDoes the question have contemporary relevance?\nDoes the question have clinical importance or importance to informing animal experiment design?\nIs there currently variation in practice?\nIs there uncertainty and debate in the field?\nInforming design of definitive animal experiment trial",
    "crumbs": [
      "Before You Start"
    ]
  },
  {
    "objectID": "wiki-content/03-b4ustart.html#has-it-been-done-before",
    "href": "wiki-content/03-b4ustart.html#has-it-been-done-before",
    "title": "Before You Start",
    "section": "Has it been done before?",
    "text": "Has it been done before?\nDo a quick search on PubMed or the most commonly used bibliographic database in your field to check for published systematic reviews. We may also check preprint archives such as bioRxiv, medRxiv or OSF, to see if a systematic review has been published as a preprint. Check for ongoing systematic reviews on PROSPERO.\nQuestions to ask regarding existing systematic reviews in the field include:\n\nHas the research question been adequately addressed?\nIs the systematic review methodology used in the review of sound quality?\nIs the research question specific or broad enough for your aim?\nHow recently was the systematic review carried out?\n\nThere is no need to start a systematic review if a recent, existing, high-quality SR answers your research question. If there is a relevant SR that is not up-to-date, consider contacting the original author team to discuss their plans for updating the review or a potential collaboration.\nFor additional reading on how to assess the quality of a published systematic review, see the PRISMA guidelines and other appropriate guidelines on the EQUATOR web-page.",
    "crumbs": [
      "Before You Start"
    ]
  },
  {
    "objectID": "wiki-content/03-b4ustart.html#is-one-already-in-progress",
    "href": "wiki-content/03-b4ustart.html#is-one-already-in-progress",
    "title": "Before You Start",
    "section": "Is one already in progress?",
    "text": "Is one already in progress?\nBefore you start, check that the review question you are interested in answering is not already being investigated by another research group.\nWhere can I find this information?\nCheck places where a systematic review protocol may be preregistered or published, e.g. PROSPERO, OSF, SyRF, preprint servers in your field e.g. bioRxiv or medRxiv. See more below: Register Your Protocol.\nIf you don’t find anything, go ahead and start your SR.\nIf you find someone is working on the same or a similar question, contact the research team. Ask about their aims, methods, and at what stage of the SR they are, and if you can collaborate to achieve the common aim.",
    "crumbs": [
      "Before You Start"
    ]
  },
  {
    "objectID": "wiki-content/03-b4ustart.html#build-your-systematic-review-team",
    "href": "wiki-content/03-b4ustart.html#build-your-systematic-review-team",
    "title": "Before You Start",
    "section": "Build your systematic review team",
    "text": "Build your systematic review team\nA systematic review can take a long time, so ensure you have the adequate expertise and funding to complete the review. Get your colleagues to help out! And reach out to people outside of your immediate team for expert advice.\n\nLibrarians: Librarians and information specialists can help with refining your search strategy. They will have insights into which bibliographic databases contain literature on the fields and topics you are interested in. Librarians can support you to identify sources for grey literature(e.g. thesis documents, technical reports, etc), and they will be able to support you to find full text versions of articles you want to include in your review, especially if they are not available with your institutional subscription.\nSystematic Review Methodologists: If you are new to the systematic review process, a methodologist will be able to help you plan and organise your review, give recommendations for software and tools, as well as meta-analysis support.\nStatistician You may require additional advice from a statistician if you plan to conduct a meta-analysis. If this is the case, it’s good to get them involved as early on in the review process as possible.\nTopic Experts: Ensure you have researchers and other stakeholders with adequate topic knowledge in your team.\nProject Managers: Undertaking a systematic review requires effective project management. Ensure there is a clear and dedicated project leader who will be overseeing the project for the entire process. The project lead maintains the overview, which stage is the review at, and invites different members onto the team when necessary.\n\n\nCollborating with your team\nEarly on in the review process, decide a naming convention for documents and decide a place for storing all documents related to the review in shared location. You may need to go back to any stage in the review and revisit decisions or find information, so keep good records. Take thorough notes of decisions made along the SR process, any deviations from the protocol. Not only is this good practice and increases transparency, it can help to make sure all team members are on the same page.",
    "crumbs": [
      "Before You Start"
    ]
  },
  {
    "objectID": "wiki-content/05-protocol.html",
    "href": "wiki-content/05-protocol.html",
    "title": "Protocol",
    "section": "",
    "text": "A systematic review protocol outlines why and how you are going to conduct your systematic review. It should include your research question, background and the systematic review methods that will be used, including plans for:\n\nsearch strategy\ninclusion and criteria\ndata extraction\nquality assessment\ndata synthesis strategy\nquantitative meta-analysis strategy (where applicable)\n\nHaving a pre-specified protocol improves the methodological transparency of your systematic review and reduces the risk of introducing bias. Publishing your protocol allows others to locate reviews in progress and enables future replication. The process of putting together your protocol often involves communication between a number of key stakeholders, you may want to discuss it with an advisory group, external experts, or your funders.",
    "crumbs": [
      "Protocol"
    ]
  },
  {
    "objectID": "wiki-content/05-protocol.html#what-is-a-protocol-and-why-have-one",
    "href": "wiki-content/05-protocol.html#what-is-a-protocol-and-why-have-one",
    "title": "Protocol",
    "section": "",
    "text": "A systematic review protocol outlines why and how you are going to conduct your systematic review. It should include your research question, background and the systematic review methods that will be used, including plans for:\n\nsearch strategy\ninclusion and criteria\ndata extraction\nquality assessment\ndata synthesis strategy\nquantitative meta-analysis strategy (where applicable)\n\nHaving a pre-specified protocol improves the methodological transparency of your systematic review and reduces the risk of introducing bias. Publishing your protocol allows others to locate reviews in progress and enables future replication. The process of putting together your protocol often involves communication between a number of key stakeholders, you may want to discuss it with an advisory group, external experts, or your funders.",
    "crumbs": [
      "Protocol"
    ]
  },
  {
    "objectID": "wiki-content/05-protocol.html#protocol-templates",
    "href": "wiki-content/05-protocol.html#protocol-templates",
    "title": "Protocol",
    "section": "Protocol templates",
    "text": "Protocol templates\nWe strongly recommend using a protocol template to ensure you have covered all the important information in your protocol. \nSYRCLE (SYstematic Review Centre for Laboratory animal Experimentation) have developed a protocol template tailored to the preparation, registration and publication of systematic reviews of animal intervention studies. See the template and publication here.\nIt may be useful to look through examples of previously published protocols from PROSPERO for Animals while you formulate your protocol. You can also use PROSPERO to check that no systematic reviews on your research question are currently underway. For examples of SYRCLE protocol templates, see the SyRF Protocol Registry while you formulate your protocol. Please note that the SyRF Protocol Registry is no longer accepting new protocol submissions. Please use PROSPERO for Animals.",
    "crumbs": [
      "Protocol"
    ]
  },
  {
    "objectID": "wiki-content/05-protocol.html#register-your-protocol",
    "href": "wiki-content/05-protocol.html#register-your-protocol",
    "title": "Protocol",
    "section": "Register your protocol",
    "text": "Register your protocol\nMaking the protocol for your systematic review available to the community has a number of benefits:\n\nit provides evidence that prespecified analyses were indeed prespecified; \nallows others to comment on your approach; provides examples for others planning such reviews; \nand can help you identify if other reviews in similar areas are already in progress.\n\n\nWe recommend reading the publication “Navigating PROSPERO4animals: 10 top tips for efficient pre-registration of your animal systematic review protocol” which is an article that aims to help authors write and register a detailed systematic review protocol on PROSPERO4animals.\n\nPROSPERO: The Centre for Reviews and Dissemination at University of York now publish Preclinical Systematic Review Protocols. You can search published protocols by title, date, contact person or institution. For more information on registering at PROSPERO, see their website here.\nOSF: You can preregister your systematic review project on the Open Science Framework here.\n\n\nYour protocol & 3Rs\nWe recommend that you include a statement in your protocol outlining how your research will impact the 3Rs (Replacement, Reduction and Refinement) in animal use in research.",
    "crumbs": [
      "Protocol"
    ]
  },
  {
    "objectID": "wiki-content/05-protocol.html#protocol-development-workshops",
    "href": "wiki-content/05-protocol.html#protocol-development-workshops",
    "title": "Protocol",
    "section": "Protocol Development Workshops",
    "text": "Protocol Development Workshops\nCAMARADES Berlin offers a range of workshops on Systematic Review and Meta-Analysis of Animal Studies, including a workshop on protocol development.\nProtocol Development for Systematic Review of Animal Studies  This workshop will cover the contents of a transparent and comprehensive preclinical systematic review protocol. It will cover the rationale behind registering your systematic review protocol and where to register. This workshop is aimed at researchers who already have a basic understanding of systematic reviews of animal data. For more information, please click here: Protocol Development for Systematic Review of Animal Studies",
    "crumbs": [
      "Protocol"
    ]
  },
  {
    "objectID": "wiki-content/07-studyselection.html",
    "href": "wiki-content/07-studyselection.html",
    "title": "Study Selection",
    "section": "",
    "text": "Once you have found articles that may be potentially relevant to your research question, you now need to assess each article for relevance against predefined criteria.\nIf applicable, you may consider doing this in two stages:",
    "crumbs": [
      "Study Selection"
    ]
  },
  {
    "objectID": "wiki-content/07-studyselection.html#inclusion-exclusion-criteria",
    "href": "wiki-content/07-studyselection.html#inclusion-exclusion-criteria",
    "title": "Study Selection",
    "section": "Inclusion & exclusion criteria",
    "text": "Inclusion & exclusion criteria\nDefining the inclusion and exclusion criteria sets the boundaries for your review.\n\nInclusion criteria refer to everything a study must have to be included in your review.\nExclusion criteria refer to factors that make a study ineligible for inclusion.\n\nIt is important the criteria are predefined, a priori, and applied consistently across all studies considered for the review. To ensure this, it is common to do citation screening in duplicate, two independent reviews, with discussion or a third independent reviewer to reconcile any discrepancies.\nCommonly your inclusion and exclusion criteria are defined around:\n\nType of study or study design\nType of population (e.g. age, sex, disease model)\nType of intervention (e.g. dosage, timing of intervention, frequency)\nType of outcome Measures (e.g. parameters related to method of assessment or apparatus)\n\nAdditional factors you may want to consider:\n\nLanguage restrictions\nPublication date restrictions\nType of publication (e.g. conference abstracts, peer-reviewed)\n\nYou may consider prioritising your inclusion and exclusion criteria based on what criteria you are likely to apply at title and abstract stage, and what criteria you can only apply after having read the full-text.",
    "crumbs": [
      "Study Selection"
    ]
  },
  {
    "objectID": "wiki-content/07-studyselection.html#apply-your-criteria",
    "href": "wiki-content/07-studyselection.html#apply-your-criteria",
    "title": "Study Selection",
    "section": "Apply your criteria",
    "text": "Apply your criteria\nIs a study included or excluded in your review? Is a study relevant, or not relevant, to your research question based on your pre-defined criteria?\nTo ensure your inclusion and exclusion criteria are applied in a unbiased, uniform fashion, it is good practice to have at least 2 independent screeners apply the criteria. If there are discrepancies in your decisions, you may discuss the discrepancies until you reach consensus or invite a 3rd independent reviewer to reconcile any differences.",
    "crumbs": [
      "Study Selection"
    ]
  },
  {
    "objectID": "wiki-content/07-studyselection.html#tools-for-screening",
    "href": "wiki-content/07-studyselection.html#tools-for-screening",
    "title": "Study Selection",
    "section": "Tools for screening",
    "text": "Tools for screening\nYou can complete title and abstract screening & full text screening in SyRF, the Systematic Review Facility, which is a free-to-use online platform to support your preclinical systematic review.\nSyRF randomly presents the order of articles to screeners and by default requires a consensus between multiple screeners.\nOther free-to-use platforms to perform citation screening include Rayyan and SysRev.",
    "crumbs": [
      "Study Selection"
    ]
  },
  {
    "objectID": "wiki-content/09-qualityassessment.html",
    "href": "wiki-content/09-qualityassessment.html",
    "title": "Quality Assessment",
    "section": "",
    "text": "Low methodological quality can affect internal validity and introduce bias into the results of primary studies. Internal validity refers to the extent to which study results reflect the true cause-effect of an intervention. Different types of bias can influence internal validity (e.g. selection, performance, detection, and attrition biases).\nIt is not impact. It is not novelty.\nBias in primary studies can lead to an over- or under-estimation of the true intervention effect in both primary studies and systematic reviews. It is important to consider the implications of study quality and validity for interpreting the results from your systematic review and it is often a good idea to incorporate a quality assessment section into your final report.\nStudy quality characteristics which have been shown to impact the results of preclinical studies include whether animals were randomised to control or treatment groups, and if researchers were blinded to intervention allocation or exposure when assessing outcomes. Read more about allocation and blinding on the NC3Rs Experimental Design Assistant website.",
    "crumbs": [
      "Quality Assessment"
    ]
  },
  {
    "objectID": "wiki-content/09-qualityassessment.html#why-assess-study-quality",
    "href": "wiki-content/09-qualityassessment.html#why-assess-study-quality",
    "title": "Quality Assessment",
    "section": "",
    "text": "Low methodological quality can affect internal validity and introduce bias into the results of primary studies. Internal validity refers to the extent to which study results reflect the true cause-effect of an intervention. Different types of bias can influence internal validity (e.g. selection, performance, detection, and attrition biases).\nIt is not impact. It is not novelty.\nBias in primary studies can lead to an over- or under-estimation of the true intervention effect in both primary studies and systematic reviews. It is important to consider the implications of study quality and validity for interpreting the results from your systematic review and it is often a good idea to incorporate a quality assessment section into your final report.\nStudy quality characteristics which have been shown to impact the results of preclinical studies include whether animals were randomised to control or treatment groups, and if researchers were blinded to intervention allocation or exposure when assessing outcomes. Read more about allocation and blinding on the NC3Rs Experimental Design Assistant website.",
    "crumbs": [
      "Quality Assessment"
    ]
  },
  {
    "objectID": "wiki-content/09-qualityassessment.html#reporting-quality",
    "href": "wiki-content/09-qualityassessment.html#reporting-quality",
    "title": "Quality Assessment",
    "section": "Reporting quality",
    "text": "Reporting quality\nYou can use a reporting quality checklist on primary studies in your systematic review.\n\nThe CAMARADES Checklist\nNature Reporting Checklist. The operationalised checklist is available here.",
    "crumbs": [
      "Quality Assessment"
    ]
  },
  {
    "objectID": "wiki-content/09-qualityassessment.html#risk-of-bias-methodological-quality",
    "href": "wiki-content/09-qualityassessment.html#risk-of-bias-methodological-quality",
    "title": "Quality Assessment",
    "section": "Risk of bias / methodological quality",
    "text": "Risk of bias / methodological quality\nUse a Risk of Bias (RoB) tool to help you evaluate the methodological quality of a primary animal experiment. Tools that have been developed to assess bias and quality in preclinical studies include the SYRCLE RoB tool.",
    "crumbs": [
      "Quality Assessment"
    ]
  },
  {
    "objectID": "wiki-content/09-qualityassessment.html#rob-assessment-to-inform-analysis",
    "href": "wiki-content/09-qualityassessment.html#rob-assessment-to-inform-analysis",
    "title": "Quality Assessment",
    "section": "RoB assessment to inform analysis",
    "text": "RoB assessment to inform analysis\nThe extent to which a study is at risk of bias can hugely impact the findings. Findings from your risk of bias assessment should inform the conclusions of your systematic review.\n\nConduct sensitivity analysis (quantitatively using meta-analysis or qualitatively)\nExclude studies at high risk of bias from the evidence synthesis (this should be done with extreme caution and prespecified in your protocol to avoid bias)\nReach an overall conclusion for each outcome as to whether the synthesised result is at high risk of bias\nUse the overall conclusion to inform the summary assessment of certainty of the evidence using e.g. GRADE approach",
    "crumbs": [
      "Quality Assessment"
    ]
  },
  {
    "objectID": "wiki-content/11-tools.html",
    "href": "wiki-content/11-tools.html",
    "title": "Tools for Systematic Review",
    "section": "",
    "text": "We highly recommend using software and tools to help you along the way. We have mentioned many tools throughout this Wiki, here is a list of all of them:\nSyRF, the Systematic Review Facility, is a free-to-use online platform to support your preclinical systematic review. Its features and auxiliary tools include:\nAdditional tools include:",
    "crumbs": [
      "Tools for Systematic Review"
    ]
  },
  {
    "objectID": "wiki-content/11-tools.html#automated-tools-for-systematic-reviews",
    "href": "wiki-content/11-tools.html#automated-tools-for-systematic-reviews",
    "title": "Tools for Systematic Review",
    "section": "Automated Tools for Systematic Reviews",
    "text": "Automated Tools for Systematic Reviews\nWith the increasing complexity and volume of research, automated tools such as machine learning and generative AI are being explored to assist in systematic reviews. These tools can help with tasks like literature screening, data extraction, and summarisation. However, it is essential to use them with caution:\n\nSupport, Not Replace Human Efforts: While these tools can improve efficiency, systematic reviews still require critical human judgment and expertise.\nValidation is Key: Any automated tool must be rigorously tested and validated within your specific field before being implemented.\nTask-Specific Assistance: Current AI-driven tools can aid in certain steps of the process but are not capable of conducting a full systematic review independently.\n\nIf you are conducting a large systematic review and are interested in training a custom machine learning algorithm, Contact us for more information.",
    "crumbs": [
      "Tools for Systematic Review"
    ]
  },
  {
    "objectID": "wiki-content/11-tools.html#systematic-online-living-evidence-summaries-soles",
    "href": "wiki-content/11-tools.html#systematic-online-living-evidence-summaries-soles",
    "title": "Tools for Systematic Review",
    "section": "Systematic Online Living Evidence Summaries (SOLES)",
    "text": "Systematic Online Living Evidence Summaries (SOLES)\nSystematic Online Living Evidence Summaries (SOLES) provide a powerful framework for maintaining up-to-date, continuously evolving evidence in a given research domain. These platforms integrate automation, machine learning, and structured data management to streamline evidence synthesis and ensure that research teams always have access to the latest findings.\nCapabilities and Benefits:\n\nAutomated Data Collection & Screening: Reduces the burden of manual searches and updates, ensuring efficiency and accuracy.\nLiving Evidence Updates: Enables real-time or scheduled updates, keeping systematic reviews current without requiring full re-analysis.\nScalability Across Domains: SOLES can be adapted to any disease area, making them valuable for both emerging fields and established research topics.\nEnhanced Collaboration: Facilitates seamless knowledge sharing among researchers, policymakers, and clinicians.\nImproved Decision-Making: Supports evidence-based policy and clinical practice by ensuring that the most recent and relevant data are accessible.\n\nFor more details on SOLES, refer to the following sources:\n\nSOLES paper Systematic Online Living Evidence Summaries.\nSOLES applied to the Alzheimer’s Disease field Hair et al., 2025.\nOverview of Public SOLES project SOLES Projects gitpage.\n\nIf your team is interested in developing a SOLES for your research domain, get in touch with us to explore potential collaborations.",
    "crumbs": [
      "Tools for Systematic Review"
    ]
  },
  {
    "objectID": "wiki-content/13-resources.html",
    "href": "wiki-content/13-resources.html",
    "title": "Resources & Links",
    "section": "",
    "text": "A SyRF is a free online platform to aid you in your systematic reviews and meta-analyses of in vivo studies.\n\nSyRF\nSyRF Help Guide",
    "crumbs": [
      "Resources & Links"
    ]
  },
  {
    "objectID": "wiki-content/13-resources.html#systematic-review-facility---camarades",
    "href": "wiki-content/13-resources.html#systematic-review-facility---camarades",
    "title": "Resources & Links",
    "section": "",
    "text": "A SyRF is a free online platform to aid you in your systematic reviews and meta-analyses of in vivo studies.\n\nSyRF\nSyRF Help Guide",
    "crumbs": [
      "Resources & Links"
    ]
  },
  {
    "objectID": "wiki-content/13-resources.html#templates-guides",
    "href": "wiki-content/13-resources.html#templates-guides",
    "title": "Resources & Links",
    "section": "Templates & Guides",
    "text": "Templates & Guides\n\nSYRCLE Protocol - Template & Paper\nBorenstein et al., 2009. Introduction to Meta-Analysis\nVesterinen et al, 2014. “Meta-analysis of data from animal studies: a practical guide.” Journal of neuroscience methods\nCochrane Handbook\nCheat sheet: We have summarized the main points of our Introduction to SR workshop in this cheat sheet, including links to relevant references and resources.",
    "crumbs": [
      "Resources & Links"
    ]
  }
]